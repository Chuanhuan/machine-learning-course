%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[fleqn,9 pt]{SelfArx} % Document font size and equations flushed left

% Decrease margins
%\addtolength{\oddsidemargin}{-0.3 in}
%\addtolength{\evensidemargin}{0 in}
%\addtolength{\textwidth}{0.8 in}
%\addtolength{\topmargin}{-0.5 in}
%\addtolength{\textheight}{1 in}

\usepackage[english]{babel} % Specify a different language here - english by default
\usepackage{lipsum} % Required to insert dummy text. To be removed otherwise
\usepackage{listings}
\usepackage{lipsum}  
\usepackage{caption}

%----------------------------------------------------------------------------------------
%	COLUMNS
%----------------------------------------------------------------------------------------
\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract
%----------------------------------------------------------------------------------------
%	COLORS
%----------------------------------------------------------------------------------------
\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

%----------------------------------------------------------------------------------------
%	HYPERLINKS
%----------------------------------------------------------------------------------------
\usepackage{hyperref} % Required for hyperlinks
\hypersetup{hidelinks,colorlinks,breaklinks=true,urlcolor=color2,citecolor=color1,linkcolor=color1,bookmarksopen=false,pdftitle={Title},pdfauthor={Author}}

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------
\JournalInfo{Project 2 - CS-433 - Road Classification with 2D Convolutional Neural Networks} % Journal information
\Archive{\today} % Additional notes (e.g. copyright, DOI, review/research article)

%%%%% dumb test
\usepackage[english]{babel}
\usepackage{blindtext}

\PaperTitle{Road Classification with 2D Conv. Neural Networks} % Article title

\Authors{Bruno Magalhaes\textsuperscript{1}, Riccardo Silini\textsuperscript{2} \hspace{7.7cm} team: OhWell} % Authors
\affiliation{\textbf{Email (SCIPER):} \hspace{0.2cm} \textsuperscript{1} bruno.magalhaes@epfl.ch (212079) \hspace{0.2cm} \textsuperscript{2} riccardo.silini@epfl.ch (214398) \hspace{0.2cm}}

\Keywords{}
%Keyword1 --- Keyword2 --- Keyword3

\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

%to allow overlapping
\usepackage[percent]{overpic}
\usepackage[]{algorithmic,algorithm2e}

%to allow \figures right below text 
\usepackage{float}

%---------- ABSTRACT

\Abstract{ \small

Road classification from orthogonal aerial photographies allows for automatic reconstruction of maps, guidance of autonomous vehicles, among others. Manual classification is infeasible due to the large amount of information and work involved. Automatic classification can be pursued with Machine Learning techniques. With that in mind, we present an algorithm for the automatic labelling of roads from sets of pictures using a 2D convolutional neural network. For added accuracy, we improve the provided sample code with data augmentation and dropout techniques and a 2-step neural network processing that learns from predictions of road labels.
}

\begin{document}
\begin{sloppypar} %allows line breaks in \texttt{---} section

\flushbottom % Makes all text pages the same height
\maketitle % Print the title and abstract box
%\tableofcontents % Print the contents section
%\thispagestyle{empty} % Removes page numbering from the first page

\section{Introduction}

Our classificator was implemented on a 2D convolutional neural network, built with the TensorFlow API. Our network is based on several (user-definable) layers of convolution followed by two layers of fully connected nodes. The input is described by a square patch of RGB pixels. The output is the probability of a given input being classified as road and non-road.
Previous attempts of classification based on Logistic Regression failed short due to not allowing for enough depth of the network to universally approximate the problem --- in practice being as performant as a fully-connected single-layer neural network. Nevertheless, its philosophy of including neighbour patches on the classification of a central patch was implemented in our model.

The parameters of the execution and the Stochastic Gradient Descent algorithm are detailed in sub-section \ref{sec-execution-parameters}. For higher precision, we increased the input size with two data augmentation techniques, generating new image patches from pre-existing rotated patches, and from interleaved intervals of existing patches, as detailed in Section \ref{sec-data-augmentation}. We evaluated our results on a Macbook Air 13.3" 2015 and collected the feedback form the Kaggle system page, as presented in the results section (\ref{sec-results}). Section \ref{sec-conclusion} draws final conclusions.

\paragraph{Execution Parameters}
\label{sec-execution-parameters}

The gradient descent algorithm parameters are the following: \texttt{LEARNING\_RATE} specifies the step size on the gradient descent update, with a decay given by \texttt{DECAY\_RATE}; the iterations count is defined in \texttt{NUM\_EPOCHS}; the value set by the variable \texttt{BATCH\_SIZE} specifies how many input elements to be used on the weights update, in practice allowing one to run Stochastic Gradient Descent by inputing a single element, a batch of elements, or all input data; \texttt{INPUT\_SIZE} sets the number of images used for training.

For labelling, \texttt{FOREGROUND\_THRESHOULD} defines the threshold of the mean gradient on a given patch to be considered as non-road;

Multi-core processing is possible by setting \texttt{NUM\_THREADS} to the respective value of maximum concurrent threads in the processor's architecture. \texttt{SEED} allows one to reproduce results by setting the random seed to the given value. The model training is stored automatically at every set of \texttt{RECORDING\_STEPS} steps. A model can be restored by setting the flag \texttt{RESTORE\_MODEL} to \texttt{True}.

\section{Data Augmentation}
\label{sec-data-augmentation}

\paragraph{1. Rotation of input images with non-orthogonal roads} We increased the number of input images from $100$ to $148$ by rotating $90 \deg$, $180 \deg$ and $270 \deg$ the (16) training images that are not composed only of non-horizontal and non-vertical roads. This feature is activated by the flag \texttt{DATA\_AUGMENTATION}.

\paragraph{2. Patches from concatenation points} We increase by almost two-fold the number of patches per training image by performing extraction of all patches of size \texttt{IMG\_PATCH\_SIZE} that are placed at every \texttt{IMG\_PATCH\_SIZE/2} interval. This feature is activated by the flag \texttt{ADD\_INTERCALATED\_PATCHES}. In practice, it extracts patches with the corners at the mid-point positions of previously extracted patches, as displayed below:

\begin{figure}[H]
\centering
\includegraphics[width=0.47\textwidth]{figures/ADD_INTERCALATED_PATCHES.pdf}
\caption{\small The collection of patches by stepping \texttt{IMG\_PATCH\_SIZE} (default, left) compared with \texttt{IMG\_PATCH\_SIZE/2} (\texttt{ADD\_INTERCALATED\_PATCHES} activated, right). When traversing image, next collected patch on the horizontal (vertical) direction is displayed as red (green).}
\end{figure}

\section{Architecture}

Our network is composed by a set of convolution layers (for extracting of convoluted features) and pooling layers (for the extraction of most meaningful weights from convolutional layer outputs), followed by two layers of fully connected layers (the universal function approximators). The input is a set of images to which patches are extracted. Those patches are then input individually or in batches to the network. The output contains the probability of the road or non-road classification. A sample of a possible network architecture with 2 convoluted layers and default parameters is displayed in figure \ref{fig-conv-2d-architecture}.

\begin{figure*}
\centering
\includegraphics[width=0.9\textwidth]{figures/conv_2d_network.png}
\caption{\small A general overview of the deep network architecture, with default parameters. Dimensionalities, padding types, depths and number of convolution+pooling layers are user-customisable.}
\label{fig-conv-2d-architecture}
\end{figure*}


\paragraph{Multi-Layer convolutional network}

We allow the sub-network of convolution layers to increase or decrease, according to the user-defined parameters \texttt{CONV\_LAYERS}. This allowed us to play with the quality of model fitting for different set set of parameters. In practice, our network is an array of convolution and pooling layers, where the output of one layer is the input of the following one. The parameters of every layer is fully customisable by the user from the following variables:
\begin{itemize}
\item \texttt{CONV\_LAYERS}: number of convolutional layers, and size of the following parameter arrays;
\item \texttt{CONV\_FILTER\_SIZES = [5,5,5,5]} : For each layer, the count of horizontal and vertical pixels of filter;
\item \texttt{CONV\_FILTER\_DEPTHS = [32, 64, 128, 256]}: depth of the weights for the aforementioned layers;
\item \texttt{POOL\_FILTER\_STRIDES = [2, 2, 2, 2]}: horizontal and vertical stride for the max-pooling on each layer;
\item \texttt{FC1\_WEIGHTS\_DEPTH = 512}: depth of the first fully connected layer, connected to conv. layer of id \texttt{CONV\_LAYERS-1}. The second layer performs binary probability classification therefore has depth \texttt{NUM\_LABELS} (road; non-road);
\end{itemize}
  This allowed us to play with the quality of fitting based on user-provided filter sizes, depths and strides -- as detailed in the following paragraph.
 
\paragraph{Two-step classification} 

To reduce noise and allows classification at a finer scale, we added a second neural network to the processing. The initial one will be trained with pairs of [images,groundtruth] and outputs the segmented classification. The second network is trained with pairs [classification,groundtruth] and received the first network's classification as input, outputting the final classification. The second step of this operation is presented as \texttt{Phase 2} in the source code. An example of an application of the two-step classification is displayed in the following picture.

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{figures/two_phases_conv2d.pdf}
\caption{\small An example of the application of the two-phase propagation process: for a given input (top-left), the predicted segmentation at output of the neural network (bottom-left) is then re-input to a second neural network trained from groundtruth images (top-right), outputting the final classification (bottom-right).}
\end{figure}

\paragraph{Analysis of neighborhood information} This functionality can be activated wit the flag \texttt{NEIGHBORHOOD\_ANALYSIS} set to \texttt{True} and definining the \texttt{NEIGHBOR\_PIXELS} to the margin of neighborhood pixels to be added and analysed from each patch.

\begin{figure}[H]
\centering
\includegraphics[width=0.47\textwidth]{figures/NEIGHBORHOOD_ANALYSIS.pdf}
\caption{\small Example of the neighborhood analysis feature. Standard classification (left) inputs patches of images and classifies the same area. With neighborhood analysis (right), we input the patch of size \texttt{IMG\_PATCH\_SIZE} and all surrounding \texttt{NEIGHBOR\_PIXELS} pixels (orange), with the learning based on the labels of the patch only (red).}
\end{figure}

\paragraph{Randomized input sequence}

The order in which we present the observations (input vectors) comprising the training set to the network affects the final computation of weights. We implemented a randomized arrangement of the observations according to the response variable that has been shows to be present a better tuned network when compared with ordered arrangements (the standard implementation). Our input is then a randomized set of classification with balanced number of inputs for each label. This feature is enabled by defining \texttt{RANDOMIZE\_INPUT\_PATCHES = True}.

\paragraph{Dropout}

Dropout is a regularization technique for reducing the overfitting of neural networks. It performs model averaging of neural networks efficiently and prevents complex co-adaptations on training data (Srivastava et at. 2014 \cite{srivastava2014dropout}). We enabled dropout in our models by specifying the percentage of dropout on the variable \texttt{DROPOUT\_RATE} as exemplified in the next figure:

\begin{figure}[H]
\centering
\includegraphics[width=0.44\textwidth]{figures/DROPOUT_RATE.pdf}
\caption{\small Example of the dropout feature. Standard weights tunning (left) methods apply an update of all weights. Dropout-based networks (right) discards the updates of certain weights with the rationale of reducing overfitting. In the example, a dropout rate of \texttt{0.5} disables half of the nodes on the network.}
\end{figure}

\section{Performance Analysis and Results}
\label{sec-results}

Riccardo bla bla bla

\section{Final Remarks and Conclusion}
\label{sec-conclusion}

bla bla bla 


%references
\bibliographystyle{unsrt}
\bibliography{report}

\end{sloppypar}
\end{document}