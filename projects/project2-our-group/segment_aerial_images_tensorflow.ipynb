{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTES*\n",
    "- Data augmentation: generare more inpute\n",
    "- Drop out... MAYBE\n",
    "- Rule of thumb: per layer, halve dimensions X*Y and double depth\n",
    "- To reduce overfitting, we will apply dropout before the readout layer.\n",
    "  TODO mention paper:Dropout: A Simple Way to Prevent Neural Networks from Overfitting\n",
    "  https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "Baseline for machine learning project on road segmentation.\n",
    "This simple baseline consits of a CNN with two convolutional+pooling layers with a soft-max loss\n",
    "Credits: Aurelien Lucchi, ETH ZÃ¼rich\n",
    "\"\"\"\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import code\n",
    "import tensorflow.python.platform\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from types import * #for assert XXX is IntTYpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 100\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16 # 64\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000\n",
    "DATA_AUGMENTATION = True\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', './tmp/', \"Directory where to write event logs and checkpoint.\")\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "EXTRA_IMAGES_ID = [23,26,27,28,30,32,33,38,42,69,72,73,75,83,88,91]\n",
    "\n",
    "if (DATA_AUGMENTATION):\n",
    "    for i in range(0, len(EXTRA_IMAGES_ID)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract patches from a given image\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "#we are training stoch gradient descent but with batches, batch size of BATCH_SIZE\n",
    "\n",
    "#return matrix of image patches\n",
    "def extract_data(filename, num_images, phase):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    if phase==1:\n",
    "        for i in range(1, num_images+1):\n",
    "            image_filename = filename + \"satImage_%.3d\" % i + \".png\"\n",
    "            if os.path.isfile(image_filename):\n",
    "                #print ('Loading ' + image_filename)\n",
    "                img = mpimg.imread(image_filename)\n",
    "                imgs.append(img)\n",
    "            else:\n",
    "                print ('File ' + image_filename + ' does not exist')\n",
    "    if phase==2:\n",
    "        for i in range(1, num_images+1):\n",
    "            image_filename = filename + \"prediction_raw_\" + str(i) + \".png\"\n",
    "            if os.path.isfile(image_filename):\n",
    "                #print ('Loading ' + image_filename)\n",
    "                img = mpimg.imread(image_filename)\n",
    "                imgs.append(img)\n",
    "            else:\n",
    "                print ('File ' + image_filename + ' does not exist')\n",
    "                \n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "\n",
    "    return numpy.asarray(data)\n",
    "        \n",
    "# Assign a label to a patch v\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "\n",
    "# Extract label images\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        image_filename = filename + \"satImage_%.3d\" % i + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "\n",
    "#returns percentage of WRONG labels (right ones stored in predictions)\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate based on dense predictions and 1-hot labels.\"\"\"\n",
    "    return 100.0 - (\n",
    "        100.0 *\n",
    "        numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1)) /\n",
    "        predictions.shape[0])\n",
    "\n",
    "# Write predictions from neural network to a file\n",
    "def write_predictions_to_file(predictions, labels, filename):\n",
    "    max_labels = numpy.argmax(labels, 1)\n",
    "    max_predictions = numpy.argmax(predictions, 1)\n",
    "    file = open(filename, \"w\")\n",
    "    n = predictions.shape[0]\n",
    "    for i in range(0, n):\n",
    "        file.write(max_labels(i) + ' ' + max_predictions(i))\n",
    "    file.close()\n",
    "\n",
    "# Print predictions from neural network\n",
    "def print_predictions(predictions, labels):\n",
    "    max_labels = numpy.argmax(labels, 1)\n",
    "    max_predictions = numpy.argmax(predictions, 1)\n",
    "    print (str(max_labels) + ' ' + str(max_predictions))\n",
    "\n",
    "# Convert array of labels to an image\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if labels[idx][0] > 0.5:\n",
    "                l = 1\n",
    "            else:\n",
    "                l = 0\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "    color_mask[:,:,0] = predicted_img*PIXEL_DEPTH\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "\n",
    "        def __init__(self):\n",
    "            self.cdata = []\n",
    "\n",
    "        def run(self, phase, conv_layers=2):\n",
    "\n",
    "            # Make an image summary for 4d tensor image with index idx\n",
    "            def get_image_summary(img, idx = 0):\n",
    "                #Take img BATCHx16x16x3 --> slice 1x16x16x1 (-1 means \"to all\")\n",
    "                #ie a single patch, all HxV pixels, single column\n",
    "                V = tf.slice(img, (0, 0, 0, idx), (1, -1, -1, 1))\n",
    "                img_w = img.get_shape().as_list()[1] #16: data was BATCH_SIZEx16x16x3\n",
    "                img_h = img.get_shape().as_list()[2]\n",
    "                min_value = tf.reduce_min(V) #gives min number across all dimensions \n",
    "                V = V - min_value  #TRANSLATION: we translate all data (start from 0)\n",
    "                max_value = tf.reduce_max(V)\n",
    "                V = V / (max_value*PIXEL_DEPTH)  #NORMALIZATION: values in 0 to 1\n",
    "                V = tf.reshape(V, (img_w, img_h, 1))\n",
    "                V = tf.transpose(V, (2, 0, 1))\n",
    "                V = tf.reshape(V, (-1, img_w, img_h, 1))\n",
    "                return V\n",
    "\n",
    "            # Make an image summary for 3d tensor image with index idx\n",
    "            def get_image_summary_3d(img):\n",
    "                V = tf.slice(img, (0, 0, 0), (1, -1, -1))\n",
    "                img_w = img.get_shape().as_list()[1]\n",
    "                img_h = img.get_shape().as_list()[2]\n",
    "                V = tf.reshape(V, (img_w, img_h, 1))\n",
    "                V = tf.transpose(V, (2, 0, 1))\n",
    "                V = tf.reshape(V, (-1, img_w, img_h, 1))\n",
    "                return V         \n",
    "            \n",
    "            # Get prediction for given input image \n",
    "            def get_prediction(img,phase, conv_layers):\n",
    "                data = numpy.asarray(img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "                data_node = tf.constant(data)\n",
    "                output = tf.nn.softmax(model(data_node,phase,conv_layers))\n",
    "                output_prediction = s.run(output)\n",
    "                img_prediction = label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, output_prediction)\n",
    "                return img_prediction\n",
    "\n",
    "            # Get a concatenation of the prediction and groundtruth for given input file\n",
    "            def get_prediction_with_groundtruth(filename, image_idx,phase,conv_layers):\n",
    "                if phase ==1:\n",
    "                    image_filename = filename + \"satImage_%.3d\" % image_idx + \".png\"\n",
    "                if phase == 2:\n",
    "                    image_filename = filename + \"prediction_raw_\" + str(image_idx) + \".png\" \n",
    "                img = mpimg.imread(image_filename)\n",
    "                img_prediction = get_prediction(img,phase,conv_layers)\n",
    "                return concatenate_images(img, img_prediction)\n",
    "                \n",
    "            # Get prediction overlaid on the original image for given input file\n",
    "            def get_prediction_with_overlay(filename, image_idx,phase,conv_layers):\n",
    "                if phase ==1:\n",
    "                    image_filename = filename + \"satImage_%.3d\" % image_idx + \".png\"\n",
    "                if phase == 2:\n",
    "                    image_filename = filename + \"prediction_raw_\" + str(image_idx) + \".png\"\n",
    "                    #image_filename = filename + \"satImage_%.3d\" % image_idx + \".png\" \n",
    "                img = mpimg.imread(image_filename)\n",
    "\n",
    "                img_prediction = get_prediction(img,phase, conv_layers)\n",
    "                oimg = make_img_overlay(img, img_prediction)\n",
    "\n",
    "                return oimg\n",
    "\n",
    "            # We will replicate the model structure for the training subgraph, as well\n",
    "            # as the evaluation subgraphs, while sharing the trainable parameters.\n",
    "            def model(data, phase, conv_layers, dropout=False, train=False):\n",
    "                \"\"\"The Model definition.\"\"\"\n",
    "                convs = [None] * conv_layers\n",
    "                relus = [None] * conv_layers\n",
    "                pools = [None] * conv_layers\n",
    "            \n",
    "                #define all convolational networks layers\n",
    "                for i in range (0, conv_layers):\n",
    "                    #2D convolution: w.T*x, x is data\n",
    "                    if i==0:\n",
    "                        convs[i] = tf.nn.conv2d(data,    ###input is data : BATCH_SIZEx16x16x3\n",
    "                                        conv_weights[i], #### 5x5x3x32\n",
    "                                        strides=[1, 1, 1, 1],\n",
    "                                        padding='SAME')\n",
    "                    else:\n",
    "                        convs[i] = tf.nn.conv2d(pools[i-1], #input is previous layers output\n",
    "                                    conv_weights[i],\n",
    "                                    strides=[1, 1, 1, 1],\n",
    "                                    padding='SAME')\n",
    "                \n",
    "                    # activity funtion: bias and rectified linear non-linearity. relu(w.T*x+b)\n",
    "                    relus[i] = tf.nn.relu(tf.nn.bias_add(convs[i], conv_biases[i]))\n",
    "                \n",
    "                    #pooling: best of CONV_POOLING_STRIDE results from every X and Y output\n",
    "                    pools[i] = tf.nn.max_pool(relus[i],\n",
    "                                      ksize  =[1, POOL_FILTER_STRIDES[i], POOL_FILTER_STRIDES[i], 1],\n",
    "                                      strides=[1, POOL_FILTER_STRIDES[i], POOL_FILTER_STRIDES[i], 1],\n",
    "                                      padding='SAME') \n",
    "\n",
    "                # Reshape the feature map cuboid into a 2D matrix to feed it to the fully connected layers.\n",
    "                last_pool = pools[conv_layers-1];\n",
    "                pool_shape = last_pool.get_shape().as_list()\n",
    "                reshape = tf.reshape(\n",
    "                    last_pool, #16x4x4x64\n",
    "                    [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]]) #[16, 16*16*64]\n",
    "\n",
    "                # Fully connected layer. Note that the '+' operation automatically broadcasts the biases.\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "                \n",
    "                # Add a 50% dropout during training only. Dropout also scales\n",
    "                # activations such that no rescaling is needed at evaluation time.\n",
    "                if train and dropout:\n",
    "                    hidden = tf.nn.dropout(hidden, DROPOUT_RATE, seed=SEED)\n",
    "                out = tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "                # During training, output data types and sizes\n",
    "                if train==True:\n",
    "                    print (\"== INFORMATION ON DIMENSIONALITY (train =\", str(train),\"):\")\n",
    "                    print (\"-- data: \", str(data.get_shape()))\n",
    "                    for i in range(0,conv_layers):\n",
    "                        print (\"-- convs[\"+str(i)+\"]:\", str(convs[i].get_shape()))\n",
    "                        print (\"-- conv_biases[\"+str(i)+\"]:\", str(conv_biases[i].get_shape()))\n",
    "                        print (\"-- conv_weights[\"+str(i)+\"]:\", str(conv_weights[i].get_shape()))\n",
    "                        print (\"-- relus[\"+str(i)+\"]:\", str(relus[i].get_shape()))\n",
    "                        print (\"-- relus[\"+str(i)+\"]:\", str(relus[i].get_shape()))\n",
    "                        print (\"-- pools[\"+str(i)+\"]:\", str(pools[i].get_shape()))\n",
    "                    print (\"-- reshape:\", str(reshape.get_shape()))\n",
    "                    print (\"-- fc1_weights:\", str(fc1_weights.get_shape()))\n",
    "                    print (\"-- hidden:\", str(hidden.get_shape()))\n",
    "                    print (\"-- fc2_weights:\", str(fc2_weights.get_shape()))\n",
    "                    print (\"-- out:\", str(out.get_shape()))\n",
    "\n",
    "                if train == True:\n",
    "                    summary_id = '_0'\n",
    "                    s_data = get_image_summary(data) #from docs: 3 channels so it's interpreted as RGB\n",
    "                    filter_summary0 = tf.image_summary('summary_data' + summary_id, s_data)\n",
    "                    s_convs = [None] * conv_layers\n",
    "                    filter_summaries = [None] * conv_layers *2\n",
    "                    s_pools = [None] * conv_layers\n",
    "                    for i in range (0, conv_layers):\n",
    "                        s_convs[i] = get_image_summary(convs[i])\n",
    "                        filter_summaries[i]   = tf.image_summary('summary_conv' + str(i) + summary_id, s_convs[i])\n",
    "                        s_pools[i] = get_image_summary(pools[i])\n",
    "                        filter_summaries[i+1] = tf.image_summary('summary_pool' + str(i) + summary_id, s_pools[i])\n",
    "                return out\n",
    "            \n",
    "            #create all convolutional network layers\n",
    "            conv_weights = [None] * conv_layers\n",
    "            conv_biases  = [None] * conv_layers\n",
    "            for i in range (0, conv_layers):\n",
    "                if i == 0 :\n",
    "                    conv_weights[i] = tf.Variable(\n",
    "                        tf.truncated_normal([CONV_FILTER_SIZES[i], CONV_FILTER_SIZES[i], NUM_CHANNELS, CONV_FILTER_DEPTHS[i]],\n",
    "                                stddev=0.1,\n",
    "                                seed=SEED)) #NOTE: this randomness allows the weights not to be started as zero (so that we can start training.. otherwise derivative is 0)\n",
    "                    conv_biases[i] = tf.Variable(tf.zeros([CONV_FILTER_DEPTHS[i]]))  #the +b in the equation above\n",
    "\n",
    "                else:\n",
    "                    conv_weights[i] = tf.Variable(\n",
    "                        tf.truncated_normal([CONV_FILTER_SIZES[i], CONV_FILTER_SIZES[i], CONV_FILTER_DEPTHS[i-1], CONV_FILTER_DEPTHS[i]],\n",
    "                                stddev=0.1,\n",
    "                                seed=SEED))  #each of 64 outputs of conv2 will be connected to 64 nodes in upper layer\n",
    "                    conv_biases[i] = tf.Variable(tf.constant(0.1, shape=[CONV_FILTER_DEPTHS[i]]))  #TODO why is it a constant?\n",
    "            \n",
    "            #create the two fully connected layers\n",
    "            fc1_pixel_size = IMG_PATCH_SIZE\n",
    "            for i in range(0, conv_layers):\n",
    "                #make sure strides and patches size are divisible\n",
    "                assert IMG_PATCH_SIZE / POOL_FILTER_STRIDES[i] % 1 == 0, \"IMG_PATCH_SIZE / POOL_FILTER_STRIDES[%r] is not an integer!\" % i\n",
    "                fc1_pixel_size /= POOL_FILTER_STRIDES[i]\n",
    "                \n",
    "            fc1_weights = tf.Variable( \n",
    "                tf.truncated_normal([int(fc1_pixel_size*fc1_pixel_size*CONV_FILTER_DEPTHS[conv_layers-1]), FC1_WEIGHTS_DEPTH],\n",
    "                                    stddev=0.1,\n",
    "                                    seed=SEED))\n",
    "            fc1_biases = tf.Variable(tf.constant(0.1, shape=[FC1_WEIGHTS_DEPTH]))\n",
    "            fc2_weights = tf.Variable(\n",
    "                tf.truncated_normal([FC1_WEIGHTS_DEPTH, NUM_LABELS],\n",
    "                                    stddev=0.1,\n",
    "                                    seed=SEED))\n",
    "            fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "\n",
    "            print(phase, \": extract_data...\")\n",
    "            if phase == 1:\n",
    "                train_data_filename = 'training/images/'\n",
    "                train_data = extract_data(train_data_filename, TRAINING_SIZE,phase)\n",
    "\n",
    "            if phase == 2:\n",
    "                train_data_filename = \"predictions_training/\"\n",
    "                train_data = extract_data(train_data_filename, TRAINING_SIZE,phase)\n",
    "\n",
    "            # Extract labels into numpy arrays.\n",
    "            print(phase, \": extract_labels...\")\n",
    "            train_labels_filename = 'training/groundtruth/' \n",
    "            train_labels = extract_labels(train_labels_filename, TRAINING_SIZE)\n",
    "\n",
    "            num_epochs = NUM_EPOCHS #iterations count\n",
    "\n",
    "            c0 = 0 #count of tiles labelled as 0\n",
    "            c1 = 0 #... as 1\n",
    "            for i in range(len(train_labels)):\n",
    "                if train_labels[i][0] == 1:\n",
    "                    c0 = c0 + 1\n",
    "                else:\n",
    "                    c1 = c1 + 1\n",
    "\n",
    "            #We are training on the same number of 1s and 0s, to avoid training data being biased!\n",
    "            print (phase,': before balancing: number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "            print(\"-- train_data (before): \", numpy.shape(train_data))\n",
    "            print(\"-- train_labels (before): \", numpy.shape(train_labels.shape))\n",
    "            min_c = min(c0, c1)\n",
    "            idx0 = [i for i, j in enumerate(train_labels) if j[0] == 1]\n",
    "            idx1 = [i for i, j in enumerate(train_labels) if j[1] == 1]\n",
    "            new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "            train_data = train_data[new_indices,:,:,:]\n",
    "            print(\"-- train_data (after): \", numpy.shape(train_data))\n",
    "            train_labels = train_labels[new_indices]\n",
    "            print(\"-- train_labels (after): \", numpy.shape(train_labels.shape))\n",
    "            train_size = train_labels.shape[0]\n",
    "\n",
    "            #TODO we should alternate it: it's training zeros and then ones!\n",
    "            #TODO try to randomize the picking of patches (its discarding \"non-road\" of last pics only...)\n",
    "            c0 = 0\n",
    "            c1 = 0\n",
    "            for i in range(len(train_labels)):\n",
    "                if train_labels[i][0] == 1:\n",
    "                    c0 = c0 + 1\n",
    "                else:\n",
    "                    c1 = c1 + 1\n",
    "            print (phase, ': after balancing: Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "            # This is where training samples and labels are fed to the graph.\n",
    "            # These placeholder nodes will be fed a batch of training data at each\n",
    "            # training step using the {feed_dict} argument to the Run() call below.\n",
    "            train_data_node = tf.placeholder(\n",
    "                tf.float32,\n",
    "                shape=(BATCH_SIZE, IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))\n",
    "            train_labels_node = tf.placeholder(tf.float32, shape=(BATCH_SIZE, NUM_LABELS))\n",
    "            train_all_data_node = tf.constant(train_data) #converting train_data to tensorflow variable\n",
    "            print(\"-- train_all_data_node:\", str(train_all_data_node.get_shape()))\n",
    "\n",
    "            # Training computation: logits + cross-entropy loss.\n",
    "            print(\"-- train_data_node:\", train_data_node.get_shape())\n",
    "            logits = model(train_data_node, phase, conv_layers, True, True) # BATCH_SIZE*16x16x3\n",
    "            print(\"-- logits =\", str(logits.get_shape()))\n",
    "            print(\"-- train_labels_node = \", str(train_labels_node.get_shape()))\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(   #softmax cross entropy is the loss function\n",
    "                logits, train_labels_node))\n",
    "            tf.scalar_summary('loss', loss)\n",
    "\n",
    "            #set up parameters for nodes\n",
    "            all_params_node  = []\n",
    "            for i in range (0, conv_layers):\n",
    "                all_params_node.append(conv_weights[i])\n",
    "                all_params_node.append(conv_biases[i])\n",
    "            all_params_node.append(fc1_weights)\n",
    "            all_params_node.append(fc1_biases)\n",
    "            all_params_node.append(fc2_weights)\n",
    "            all_params_node.append(fc2_biases)\n",
    "\n",
    "            all_params_names = []\n",
    "            for i in range (0, conv_layers):\n",
    "                all_params_names.append('conv_weights['+str(i)+']')\n",
    "                all_params_names.append('conv_biases['+str(i)+']')\n",
    "            all_params_names.append('fc1_weights')\n",
    "            all_params_names.append('fc1_biases')\n",
    "            all_params_names.append('fc2_weights')\n",
    "            all_params_names.append('fc2_biases')\n",
    "            all_grads_node = tf.gradients(loss, all_params_node)\n",
    "            all_grad_norms_node = [None] * conv_layers\n",
    "            for i in range(0, len(all_grads_node)):\n",
    "                norm_grad_i = tf.global_norm([all_grads_node[i]])\n",
    "                all_grad_norms_node.append(norm_grad_i)\n",
    "                tf.scalar_summary(all_params_names[i], norm_grad_i)\n",
    "\n",
    "            # L2 regularization for the fully connected parameters.\n",
    "            #### avoid extrploding weights (\"it only makes changes to the weights if they will really make a difference\")\n",
    "            regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                            tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "\n",
    "            # Add the regularization term to the loss.\n",
    "            loss += 5e-4 * regularizers\n",
    "\n",
    "            # Optimizer: set up a variable that's incremented once per batch and controls the learning rate decay.\n",
    "            batch = tf.Variable(0)\n",
    "            # Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "            learning_rate = tf.train.exponential_decay(\n",
    "                LEARNING_RATE,       # Base learning rate.\n",
    "                batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                train_size,          # Decay step.\n",
    "                DECAY_RATE,          # Decay of the step size\n",
    "                staircase=True)\n",
    "            tf.scalar_summary('learning_rate', learning_rate)\n",
    "\n",
    "            # Use simple momentum for the optimization.\n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate,0.0).minimize(loss, global_step=batch)\n",
    "\n",
    "            # Predictions for the minibatch, validation set and test set.\n",
    "            train_prediction = tf.nn.softmax(logits)\n",
    "            \n",
    "            # We'll compute them only once in a while by calling their {eval()} method.\n",
    "            train_all_prediction = tf.nn.softmax(model(train_all_data_node,phase, conv_layers))\n",
    "\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            # Create a local session to run this computation.\n",
    "            with tf.Session() as s:\n",
    "\n",
    "                if RESTORE_MODEL:\n",
    "                    # Restore variables from disk.\n",
    "                    saver.restore(s, FLAGS.train_dir + \"/model.ckpt\")\n",
    "                    print(\"Model restored.\")\n",
    "\n",
    "                else:\n",
    "                    # Run all the initializers to prepare the trainable parameters.\n",
    "                    #tf.initialize_all_variables().run()\n",
    "                    tf.global_variables_initializer().run()\n",
    "\n",
    "                    # Build the summary operation based on the TF collection of Summaries.\n",
    "                    summary_op = tf.merge_all_summaries()\n",
    "                    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\n",
    "                                                            graph=s.graph)\n",
    "                                                            #graph_def=s.graph_def)\n",
    "                    # Loop through training steps.\n",
    "                    print ('Initialized: total number of iterations = ' + str(int(num_epochs * train_size / BATCH_SIZE)))\n",
    "\n",
    "                    training_indices = range(train_size)\n",
    "\n",
    "                    for iepoch in range(num_epochs):\n",
    "\n",
    "                        # Permute training indices\n",
    "                        perm_indices = numpy.random.permutation(training_indices)\n",
    "\n",
    "                        for step in range (int(train_size / BATCH_SIZE)):\n",
    "\n",
    "                            offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "                            batch_indices = perm_indices[offset:(offset + BATCH_SIZE)]\n",
    "\n",
    "                            # Compute the offset of the current minibatch in the data.\n",
    "                            # Note that we could use better randomization across epochs.\n",
    "                            batch_data = train_data[batch_indices, :, :, :]\n",
    "                            batch_labels = train_labels[batch_indices]\n",
    "                            # This dictionary maps the batch data (as a numpy array) to the\n",
    "                            # node in the graph is should be fed to.\n",
    "                            feed_dict = {train_data_node: batch_data,\n",
    "                                         train_labels_node: batch_labels}\n",
    "\n",
    "                            if step % RECORDING_STEP == 0:\n",
    "                                summary_str, _, l, lr, predictions = s.run(\n",
    "                                    [summary_op, optimizer, loss, learning_rate, train_prediction],\n",
    "                                    feed_dict=feed_dict)\n",
    "                                #summary_str = s.run(summary_op, feed_dict=feed_dict) #TODO uncomment this? what does it do?\n",
    "                                summary_writer.add_summary(summary_str, step)\n",
    "                                summary_writer.flush()\n",
    "\n",
    "                                # print_predictions(predictions, batch_labels)\n",
    "\n",
    "                                print ('Epoch: ', iepoch,'.',step,', minibatch loss: %.3f' % (l), ', Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))\n",
    "\n",
    "                                sys.stdout.flush()\n",
    "                            else:\n",
    "                                # Run the graph and fetch some of the nodes.\n",
    "                                _, l, lr, predictions = s.run(\n",
    "                                    [optimizer, loss, learning_rate, train_prediction],\n",
    "                                    feed_dict=feed_dict)\n",
    "\n",
    "                        # Save the variables to disk.\n",
    "                        save_path = saver.save(s, FLAGS.train_dir + \"/model.ckpt\")\n",
    "                        print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "                print (\"Running prediction on training set, outputing\", TRAINING_SIZE,\"files\")\n",
    "                prediction_training_dir = \"predictions_training/\"\n",
    "                if not os.path.isdir(prediction_training_dir):\n",
    "                    os.mkdir(prediction_training_dir)\n",
    "                for i in range(1, TRAINING_SIZE+1):\n",
    "\n",
    "                    if phase ==1:\n",
    "                        image_filename = train_data_filename + \"satImage_%.3d\" % i + \".png\"\n",
    "                    if phase == 2:\n",
    "                        image_filename = train_data_filename + \"prediction_raw_\" + str(i) + \".png\" \n",
    "\n",
    "                    pimg = get_prediction_with_groundtruth(train_data_filename,i,phase,conv_layers)\n",
    "\n",
    "                    rimg = mpimg.imread(image_filename)\n",
    "                    rimg_prediction = get_prediction(rimg,phase, conv_layers)\n",
    "                    #convert from 2D array 1/0 to RGB\n",
    "                    w = rimg_prediction.shape[0]\n",
    "                    h = rimg_prediction.shape[1]\n",
    "                    rimg_mask = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "                    rimg_mask[:,:,0] = rimg_prediction*PIXEL_DEPTH\n",
    "                    rimg_mask[:,:,1] = rimg_prediction*PIXEL_DEPTH\n",
    "                    rimg_mask[:,:,2] = rimg_prediction*PIXEL_DEPTH\n",
    "                    rimg_final = Image.fromarray(rimg_mask, 'RGB')    \n",
    "                    \n",
    "                    oimg = get_prediction_with_overlay(train_data_filename,i,phase,conv_layers)\n",
    "                    \n",
    "                    if phase == 1:\n",
    "                        Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "                        rimg_final.save(prediction_training_dir + \"prediction_raw_\" + str(i) + \".png\")\n",
    "                        oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
    "                    if phase == 2:\n",
    "                        Image.fromarray(pimg).save(prediction_training_dir + \"prediction_2_\" + str(i) + \".png\")\n",
    "                        rimg_final.save(prediction_training_dir + \"prediction_raw_2_\" + str(i) + \".png\")\n",
    "                        oimg.save(prediction_training_dir + \"overlay_2_\" + str(i) + \".png\")\n",
    "\n",
    "            print(\"-- job done --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : extract_data...\n",
      "1 : extract_labels...\n",
      "1 : before balancing: number of data points per class: c0 = 46309 c1 = 16191\n",
      "-- train_data (before):  (62500, 16, 16, 3)\n",
      "-- train_labels (before):  (2,)\n",
      "-- train_data (after):  (32382, 16, 16, 3)\n",
      "-- train_labels (after):  (2,)\n",
      "1 : after balancing: Number of data points per class: c0 = 16191 c1 = 16191\n",
      "-- train_all_data_node: (32382, 16, 16, 3)\n",
      "-- train_data_node: (16, 16, 16, 3)\n",
      "== INFORMATION ON DIMENSIONALITY (train = True ):\n",
      "-- data:  (16, 16, 16, 3)\n",
      "-- convs[0]: (16, 16, 16, 32)\n",
      "-- conv_biases[0]: (32,)\n",
      "-- conv_weights[0]: (5, 5, 3, 32)\n",
      "-- relus[0]: (16, 16, 16, 32)\n",
      "-- relus[0]: (16, 16, 16, 32)\n",
      "-- pools[0]: (16, 8, 8, 32)\n",
      "-- convs[1]: (16, 8, 8, 64)\n",
      "-- conv_biases[1]: (64,)\n",
      "-- conv_weights[1]: (5, 5, 32, 64)\n",
      "-- relus[1]: (16, 8, 8, 64)\n",
      "-- relus[1]: (16, 8, 8, 64)\n",
      "-- pools[1]: (16, 4, 4, 64)\n",
      "-- convs[2]: (16, 4, 4, 128)\n",
      "-- conv_biases[2]: (128,)\n",
      "-- conv_weights[2]: (5, 5, 64, 128)\n",
      "-- relus[2]: (16, 4, 4, 128)\n",
      "-- relus[2]: (16, 4, 4, 128)\n",
      "-- pools[2]: (16, 2, 2, 128)\n",
      "-- reshape: (16, 512)\n",
      "-- fc1_weights: (512, 512)\n",
      "-- hidden: (16, 512)\n",
      "-- fc2_weights: (512, 2)\n",
      "-- out: (16, 2)\n",
      "-- logits = (16, 2)\n",
      "-- train_labels_node =  (16, 2)\n",
      "Initialized: total number of iterations = 6071\n",
      "Epoch:  0 . 0 , minibatch loss: 3.376 , Minibatch error: 50.0%\n",
      "Epoch:  0 . 1000 , minibatch loss: 1.222 , Minibatch error: 50.0%\n",
      "Epoch:  0 . 2000 , minibatch loss: 1.107 , Minibatch error: 25.0%\n",
      "Model saved in file: ./tmp//model.ckpt\n",
      "Epoch:  1 . 0 , minibatch loss: 1.228 , Minibatch error: 56.2%\n",
      "Epoch:  1 . 1000 , minibatch loss: 0.956 , Minibatch error: 18.8%\n",
      "Epoch:  1 . 2000 , minibatch loss: 1.077 , Minibatch error: 31.2%\n",
      "Model saved in file: ./tmp//model.ckpt\n",
      "Epoch:  2 . 0 , minibatch loss: 0.990 , Minibatch error: 18.8%\n",
      "Epoch:  2 . 1000 , minibatch loss: 1.179 , Minibatch error: 37.5%\n",
      "Epoch:  2 . 2000 , minibatch loss: 1.133 , Minibatch error: 37.5%\n",
      "Model saved in file: ./tmp//model.ckpt\n",
      "Running prediction on training set, outputing 100 files\n",
      "-- job done --\n"
     ]
    }
   ],
   "source": [
    "## CNN settings:\n",
    "IMG_PATCH_SIZE = 16 #should be a multiple of 4 and img_size (400)\n",
    "CONV_LAYERS=3\n",
    "CONV_FILTER_SIZES = [5, 5, 5, 5] #size of X*Y filter in conv[i]\n",
    "CONV_FILTER_DEPTHS = [32, 64, 128, 256] #depth of conv_weights[i]\n",
    "POOL_FILTER_STRIDES = [2, 2, 2, 2] #stride for pooling\n",
    "FC1_WEIGHTS_DEPTH = 512 #depth of weights in fully connected 1 (before out)\n",
    "\n",
    "#Learning settings\n",
    "DROPOUT_RATE = 0.5 #amount of nodes we drop during training\n",
    "LEARNING_RATE = 0.01\n",
    "DECAY_RATE = 0.95 #decay of step size of gradient descent\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "#execute phase 1 (train inputs)\n",
    "cnn1 = CNN()\n",
    "cnn1.run(phase=1, conv_layers=CONV_LAYERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CNN settings:\n",
    "IMG_PATCH_SIZE = 16 #should be a multiple of 4 and img_size (400)\n",
    "CONV_LAYERS=2\n",
    "CONV_FILTER_SIZES = [5, 5, 5, 5] #size of X*Y filter in conv[i]\n",
    "CONV_FILTER_DEPTHS = [32, 64, 128, 256] #depth of conv_weights[i]\n",
    "POOL_FILTER_STRIDES = [2,2, 2, 2] #stride for pooling\n",
    "FC1_WEIGHTS_DEPTH = 512 #depth of weights in fully connected 1 (before out)\n",
    "\n",
    "#Learning settings\n",
    "DROPOUT_RATE = 0.5 #amount of nodes we drop during training\n",
    "LEARNING_RATE = 0.05\n",
    "DECAY_RATE = 0.95 #decay of step size of gradient descent\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "#execute phase 1 (train inputs)\n",
    "cnn1 = CNN()\n",
    "cnn1.run(phase=2, conv_layers=CONV_LAYERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask_to_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = IMG_PATCH_SIZE\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "submission_filename = 'dummy_submission.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'training/groundtruth/satImage_' + '%.3d' % i + '.png'\n",
    "    print image_filename\n",
    "    image_filenames.append(image_filename)\n",
    "    \n",
    "masks_to_submission(submission_filename, *image_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################## from Log regression code ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
