{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTES*\n",
    "- Data augmentation: generare more inpute\n",
    "- Drop out... MAYBE\n",
    "- Rule of thumb: per layer, halve dimensions X*Y and double depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "Baseline for machine learning project on road segmentation.\n",
    "This simple baseline consits of a CNN with two convolutional+pooling layers with a soft-max loss\n",
    "Credits: Aurelien Lucchi, ETH ZÃ¼rich\n",
    "\"\"\"\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import code\n",
    "import tensorflow.python.platform\n",
    "import numpy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 74 #TODO 100\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 5  #Iterations over the entire dataset\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', './tmp/', \"Directory where to write event logs and checkpoint.\")\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CNN settings:\n",
    "\n",
    "IMG_PATCH_SIZE = 16 #should be a multiple of 4 and img_size (400)\n",
    "CONV1_FILTER_SIZE = 5 # size of X*Y filter in conv1\n",
    "CONV2_FILTER_SIZE = 5 # size of X*Y filter in conv2\n",
    "CONV1_FILTER_DEPTH = 32 #depth of conv1_weights depth in conv1\n",
    "POOL1_FILTER_STRIDE = 2\n",
    "CONV2_FILTER_DEPTH = 64 #depth of conv2_weights depth in conv2\n",
    "POOL2_FILTER_STRIDE = 2\n",
    "FC1_WEIGHTS_DEPTH = 512 #depht of weights in fc1\n",
    "LEARNING_RATE = 0.01\n",
    "DECAY_RATE = 0.95 #decay of step size of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract patches from a given image\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "#we are training stoch gradient descent but with batches, batch size of BATCH_SIZE\n",
    "\n",
    "#return matrix of image patches\n",
    "def extract_data(filename, num_images, phase):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    if phase==1:\n",
    "        for i in range(1, num_images+1):\n",
    "            image_filename = filename + \"satImage_%.3d\" % i + \".png\"\n",
    "            if os.path.isfile(image_filename):\n",
    "                #print ('Loading ' + image_filename)\n",
    "                img = mpimg.imread(image_filename)\n",
    "                imgs.append(img)\n",
    "            else:\n",
    "                print ('File ' + image_filename + ' does not exist')\n",
    "    if phase==2:\n",
    "        for i in range(1, num_images+1):\n",
    "            image_filename = filename + \"prediction_raw_\" + str(i) + \".png\"\n",
    "            if os.path.isfile(image_filename):\n",
    "                #print ('Loading ' + image_filename)\n",
    "                img = mpimg.imread(image_filename)\n",
    "                imgs.append(img)\n",
    "            else:\n",
    "                print ('File ' + image_filename + ' does not exist')\n",
    "                \n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "\n",
    "    return numpy.asarray(data)\n",
    "        \n",
    "# Assign a label to a patch v\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "\n",
    "# Extract label images\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        image_filename = filename + \"satImage_%.3d\" % i + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "\n",
    "#returns percentage of WRONG labels (right ones stored in predictions)\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate based on dense predictions and 1-hot labels.\"\"\"\n",
    "    return 100.0 - (\n",
    "        100.0 *\n",
    "        numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1)) /\n",
    "        predictions.shape[0])\n",
    "\n",
    "# Write predictions from neural network to a file\n",
    "def write_predictions_to_file(predictions, labels, filename):\n",
    "    max_labels = numpy.argmax(labels, 1)\n",
    "    max_predictions = numpy.argmax(predictions, 1)\n",
    "    file = open(filename, \"w\")\n",
    "    n = predictions.shape[0]\n",
    "    for i in range(0, n):\n",
    "        file.write(max_labels(i) + ' ' + max_predictions(i))\n",
    "    file.close()\n",
    "\n",
    "# Print predictions from neural network\n",
    "def print_predictions(predictions, labels):\n",
    "    max_labels = numpy.argmax(labels, 1)\n",
    "    max_predictions = numpy.argmax(predictions, 1)\n",
    "    print (str(max_labels) + ' ' + str(max_predictions))\n",
    "\n",
    "# Convert array of labels to an image\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if labels[idx][0] > 0.5:\n",
    "                l = 1\n",
    "            else:\n",
    "                l = 0\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "    color_mask[:,:,0] = predicted_img*PIXEL_DEPTH\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "\n",
    "        def __init__(self):\n",
    "            self.data = []\n",
    "\n",
    "        def run(self, phase):\n",
    "\n",
    "            # Make an image summary for 4d tensor image with index idx\n",
    "            def get_image_summary(img, idx = 0):\n",
    "                #Take img BATCHx16x16x3 --> slice 1x16x16x1 (-1 means \"to all\")\n",
    "                #ie a single patch, all HxV pixels, single column\n",
    "                V = tf.slice(img, (0, 0, 0, idx), (1, -1, -1, 1))\n",
    "                img_w = img.get_shape().as_list()[1] #16: data was BATCH_SIZEx16x16x3\n",
    "                img_h = img.get_shape().as_list()[2]\n",
    "                min_value = tf.reduce_min(V) #gives min number across all dimensions \n",
    "                V = V - min_value  #TRANSLATION: we translate all data (start from 0)\n",
    "                max_value = tf.reduce_max(V)\n",
    "                V = V / (max_value*PIXEL_DEPTH)  #NORMALIZATION: values in 0 to 1\n",
    "                V = tf.reshape(V, (img_w, img_h, 1))\n",
    "                V = tf.transpose(V, (2, 0, 1))\n",
    "                V = tf.reshape(V, (-1, img_w, img_h, 1))\n",
    "                return V\n",
    "\n",
    "            # Make an image summary for 3d tensor image with index idx\n",
    "            def get_image_summary_3d(img):\n",
    "                V = tf.slice(img, (0, 0, 0), (1, -1, -1))\n",
    "                img_w = img.get_shape().as_list()[1]\n",
    "                img_h = img.get_shape().as_list()[2]\n",
    "                V = tf.reshape(V, (img_w, img_h, 1))\n",
    "                V = tf.transpose(V, (2, 0, 1))\n",
    "                V = tf.reshape(V, (-1, img_w, img_h, 1))\n",
    "                return V         \n",
    "            \n",
    "            # Get prediction for given input image \n",
    "            def get_prediction(img,phase):\n",
    "                data = numpy.asarray(img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "                data_node = tf.constant(data)\n",
    "                output = tf.nn.softmax(model(data_node,phase))\n",
    "                output_prediction = s.run(output)\n",
    "                img_prediction = label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, output_prediction)\n",
    "                return img_prediction\n",
    "\n",
    "            # Get a concatenation of the prediction and groundtruth for given input file\n",
    "            def get_prediction_with_groundtruth(filename, image_idx,phase):\n",
    "                if phase ==1:\n",
    "                    image_filename = filename + \"satImage_%.3d\" % image_idx + \".png\"\n",
    "                if phase == 2:\n",
    "                    image_filename = filename + \"prediction_raw_\" + str(image_idx) + \".png\" \n",
    "                img = mpimg.imread(image_filename)\n",
    "                img_prediction = get_prediction(img,phase)\n",
    "                return concatenate_images(img, img_prediction)\n",
    "                \n",
    "            # Get prediction overlaid on the original image for given input file\n",
    "            def get_prediction_with_overlay(filename, image_idx,phase):\n",
    "                if phase ==1:\n",
    "                    image_filename = filename + \"satImage_%.3d\" % image_idx + \".png\"\n",
    "                if phase == 2:\n",
    "                    image_filename = filename + \"prediction_raw_\" + str(image_idx) + \".png\" \n",
    "                img = mpimg.imread(image_filename)\n",
    "\n",
    "                img_prediction = get_prediction(img,phase)\n",
    "                oimg = make_img_overlay(img, img_prediction)\n",
    "\n",
    "                return oimg\n",
    "\n",
    "            # We will replicate the model structure for the training subgraph, as well\n",
    "            # as the evaluation subgraphs, while sharing the trainable parameters.\n",
    "            def model(data, phase, train=False):\n",
    "                \"\"\"The Model definition.\"\"\"\n",
    "                # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "                # the same size as the input). Note that {strides} is a 4D array whose\n",
    "                # shape matches the data layout: [image index, y, x, depth].\n",
    "\n",
    "                #REMINDER: conv2d takes\n",
    "                #- input tensor of shape [batch, in_height, in_width, in_channels],\n",
    "                #- filter/kernel of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "                #computes a 2D convolution given a 4D input and tensor\n",
    "                #Returns a tensor. Has the same type as input.\n",
    "                conv = tf.nn.conv2d(data,  ###size BATCH_SIZEx16x16x3 (placeholder)\n",
    "                                    conv1_weights,  #### 5x5x3x32\n",
    "                                    strides=[1, 1, 1, 1],  ###BATCH index, X, Y and channel strides\n",
    "                                    padding='SAME')\n",
    "\n",
    "                # activity funtion: bias and rectified linear non-linearity.\n",
    "                relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases)) ### relu is a type of sigmoid that is rectifier (plot similar to Hinge' loss)\n",
    "                # Max pooling. The kernel size spec {ksize} also follows the layout of\n",
    "                # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "\n",
    "                ### conv1 outputs 5x5xCHANNELSx32, we get 4 inputs instead ou \n",
    "                ### pooling ignores some outputs from layer1, for dimensionality reduction\n",
    "                pool = tf.nn.max_pool(relu,\n",
    "                                      ksize=[1, POOL1_FILTER_STRIDE, POOL1_FILTER_STRIDE, 1], ###kernel size, we take the best out of every 2 X and Y dimensions \n",
    "                                                          ## and use that as input to conv2 (it does not reduce input size, just remove less important outputs from conv1)\n",
    "                                                          ##, this still leads to same size of input matrix after multiplication\n",
    "                                      strides=[1, POOL1_FILTER_STRIDE, POOL1_FILTER_STRIDE, 1],\n",
    "                                      padding='SAME') #how to handle corner cases: 'VALID' uses only possible tiles (drops corner cases), 'SAME' uses zero\n",
    "\n",
    "                conv2 = tf.nn.conv2d(pool,  #pool of conv1 is the input to conv2  ### conv2d internally does the multiplication\n",
    "                                    conv2_weights,\n",
    "                                    strides=[1, 1, 1, 1],\n",
    "                                    padding='SAME')\n",
    "                relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "                pool2 = tf.nn.max_pool(relu2,\n",
    "                                      ksize=[1, POOL2_FILTER_STRIDE, POOL2_FILTER_STRIDE, 1],\n",
    "                                      strides=[1, POOL2_FILTER_STRIDE, POOL2_FILTER_STRIDE, 1], #strides are on conv1 now\n",
    "                                      padding='SAME')\n",
    "\n",
    "                # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "                # fully connected layers.\n",
    "                pool_shape = pool2.get_shape().as_list()\n",
    "                reshape = tf.reshape(\n",
    "                    pool2, #16x4x4x64\n",
    "                    [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "                   #[16, 16*16*64]\n",
    "\n",
    "                ### We have to re-shape it so that we can pass it to a fully connected layer\n",
    "                # Fully connected layer. Note that the '+' operation automatically\n",
    "                # broadcasts the biases.\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "                # Add a 50% dropout during training only. Dropout also scales\n",
    "                # activations such that no rescaling is needed at evaluation time.\n",
    "\n",
    "                #### the idea of dropout is that it ignores some random outputs at the end;\n",
    "                #### the idea is that when we have some kind of noise, this randomness removes noise (debatable)\n",
    "                #if train:\n",
    "                #    hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "                out = tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "                # Uncomment these lines to check the size of each layer\n",
    "                if train==True:\n",
    "                    print (\"==== train:\", str(train))\n",
    "                    print (\"data: \", str(data.get_shape()))\n",
    "                    print (\"conv: \", str(conv.get_shape()))\n",
    "                    print (\"conv1_biases:\", str(conv1_biases.get_shape()))\n",
    "                    print (\"conv1_weights:\", str(conv1_weights.get_shape()))\n",
    "                    print (\"relu: \", str(relu.get_shape()))\n",
    "                    print (\"pool: \", str(pool.get_shape()))\n",
    "                    print (\"conv2: \", str(conv2.get_shape()))\n",
    "                    print (\"conv2_biases:\", str(conv2_biases.get_shape()))\n",
    "                    print (\"conv2_weights:\", str(conv2_weights.get_shape()))\n",
    "                    print (\"relu2: \", str(relu2.get_shape()))\n",
    "                    print (\"pool2:\", str(pool2.get_shape()))\n",
    "                    print (\"reshape:\", str(reshape.get_shape()))\n",
    "                    print (\"fc1_weights:\", str(fc1_weights.get_shape()))\n",
    "                    print (\"hidden:\", str(hidden.get_shape()))\n",
    "                    print (\"fc2_weights:\", str(fc2_weights.get_shape()))\n",
    "                    print (\"out:\", str(out.get_shape()))\n",
    "\n",
    "                if train == True:\n",
    "                    summary_id = '_0'\n",
    "                    s_data = get_image_summary(data) #from docs: 3 channels so it's interpreted as RGB\n",
    "                    filter_summary0 = tf.image_summary('summary_data' + summary_id, s_data)\n",
    "                    s_conv = get_image_summary(conv)\n",
    "                    filter_summary2 = tf.image_summary('summary_conv' + summary_id, s_conv)\n",
    "                    s_pool = get_image_summary(pool)\n",
    "                    filter_summary3 = tf.image_summary('summary_pool' + summary_id, s_pool)\n",
    "                    s_conv2 = get_image_summary(conv2)\n",
    "                    filter_summary4 = tf.image_summary('summary_conv2' + summary_id, s_conv2)\n",
    "                    s_pool2 = get_image_summary(pool2)\n",
    "                    filter_summary5 = tf.image_summary('summary_pool2' + summary_id, s_pool2)\n",
    "                return out\n",
    "            \n",
    "            conv1_weights = tf.Variable(\n",
    "            tf.truncated_normal([CONV1_FILTER_SIZE, CONV1_FILTER_SIZE, NUM_CHANNELS, CONV1_FILTER_DEPTH],  # 5x5 filter, depth 32. ---> initializing ONLY ONE CONVOLUTIONAL LAYER\n",
    "                                stddev=0.1,\n",
    "                                seed=SEED)) #NOTE: this randomness allows the weights not to be started as zero (so that we can start training.. otherwise derivative is 0)\n",
    "\n",
    "            conv1_biases = tf.Variable(tf.zeros([CONV1_FILTER_DEPTH]))  #the +b in the equation above\n",
    "            conv2_weights = tf.Variable( #this is the SECOND LAYER, takes conv1 output as input\n",
    "                tf.truncated_normal([CONV2_FILTER_SIZE, CONV2_FILTER_SIZE, CONV1_FILTER_DEPTH, CONV2_FILTER_DEPTH],  #32 inputs because in conv1 each weight will be connected to 32 diff inputs\n",
    "                                    stddev=0.1,\n",
    "                                    seed=SEED))  #each of 64 outputs of conv2 will be connected to 64 nodes in upper layer\n",
    "            conv2_biases = tf.Variable(tf.constant(0.1, shape=[CONV2_FILTER_DEPTH]))  #TODO why is it a constant?\n",
    "            fc1_weights = tf.Variable(  # Fully Connected, depth 512. # layer above conv2\n",
    "                tf.truncated_normal([int(IMG_PATCH_SIZE / (POOL1_FILTER_STRIDE*POOL2_FILTER_STRIDE) * IMG_PATCH_SIZE / (POOL1_FILTER_STRIDE*POOL2_FILTER_STRIDE) * CONV2_FILTER_DEPTH), FC1_WEIGHTS_DEPTH],\n",
    "                                    stddev=0.1,\n",
    "                                    seed=SEED))\n",
    "            fc1_biases = tf.Variable(tf.constant(0.1, shape=[FC1_WEIGHTS_DEPTH])) #layer above fc1\n",
    "            fc2_weights = tf.Variable(\n",
    "                tf.truncated_normal([FC1_WEIGHTS_DEPTH, NUM_LABELS],\n",
    "                                    stddev=0.1,\n",
    "                                    seed=SEED))\n",
    "            fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "\n",
    "            if phase == 1:\n",
    "                # Extract it into numpy arrays.\n",
    "                print(\"1: extract_data...\")\n",
    "                train_data_filename = 'training/images/'\n",
    "                train_data = extract_data(train_data_filename, TRAINING_SIZE,phase)\n",
    "\n",
    "            if phase == 2:\n",
    "                print(\"2: extract_data...\")\n",
    "                train_data_filename = \"predictions_training/\"\n",
    "                train_data = extract_data(train_data_filename, TRAINING_SIZE,phase)\n",
    "\n",
    "            print(\"train_data (before): \", numpy.shape(train_data))\n",
    "\n",
    "            # Extract labels into numpy arrays.\n",
    "            print(\"extract_labels...\")\n",
    "            train_labels_filename = 'training/groundtruth/' \n",
    "            train_labels = extract_labels(train_labels_filename, TRAINING_SIZE)\n",
    "            print(\"train_labels (before): \", numpy.shape(train_labels.shape))\n",
    "\n",
    "            num_epochs = NUM_EPOCHS #iterations count\n",
    "\n",
    "            c0 = 0 #count of tiles labelled as 0\n",
    "            c1 = 0 #... as 1\n",
    "            for i in range(len(train_labels)):\n",
    "                if train_labels[i][0] == 1:\n",
    "                    c0 = c0 + 1\n",
    "                else:\n",
    "                    c1 = c1 + 1\n",
    "            print ('Initial: number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "            #We are training on the same number of 1s and 0s, to avoid training data being biased!\n",
    "            print ('Balancing training data...')\n",
    "            min_c = min(c0, c1)\n",
    "            idx0 = [i for i, j in enumerate(train_labels) if j[0] == 1]\n",
    "            idx1 = [i for i, j in enumerate(train_labels) if j[1] == 1]\n",
    "            new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "            print (len(new_indices))\n",
    "            print (train_data.shape)\n",
    "            train_data = train_data[new_indices,:,:,:]\n",
    "            print(\"train_data (after): \", numpy.shape(train_data))\n",
    "            train_labels = train_labels[new_indices]\n",
    "            print(\"train_labels (after): \", numpy.shape(train_labels.shape))\n",
    "            train_size = train_labels.shape[0]\n",
    "\n",
    "            #TODO we should alternate it: it's training zeros and then ones!\n",
    "            #TODO try to randomize the picking of patches (its discarding \"non-road\" of last pics only...)\n",
    "            c0 = 0\n",
    "            c1 = 0\n",
    "            for i in range(len(train_labels)):\n",
    "                if train_labels[i][0] == 1:\n",
    "                    c0 = c0 + 1\n",
    "                else:\n",
    "                    c1 = c1 + 1\n",
    "            print ('After Balancing: Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "            # This is where training samples and labels are fed to the graph.\n",
    "            # These placeholder nodes will be fed a batch of training data at each\n",
    "            # training step using the {feed_dict} argument to the Run() call below.\n",
    "            train_data_node = tf.placeholder(\n",
    "                tf.float32,\n",
    "                shape=(BATCH_SIZE, IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))\n",
    "            train_labels_node = tf.placeholder(tf.float32, shape=(BATCH_SIZE, NUM_LABELS))\n",
    "            train_all_data_node = tf.constant(train_data) #just converting train_data to tensorflow variable system\n",
    "            print(\"train_all_data_node\", str(train_all_data_node.get_shape()))\n",
    "\n",
    "            # Training computation: logits + cross-entropy loss.\n",
    "            print(\"train_data_node:\", train_data_node.get_shape())\n",
    "            logits = model(train_data_node, phase, True) # BATCH_SIZE*16x16x3\n",
    "            print(\"logits =\", str(logits.get_shape()), \" train_labels_node = \", str(train_labels_node.get_shape()))\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(   #softmax cross entropy is the loss function\n",
    "                logits, train_labels_node))\n",
    "            tf.scalar_summary('loss', loss)\n",
    "\n",
    "            all_params_node = [conv1_weights, conv1_biases, conv2_weights, conv2_biases, fc1_weights, fc1_biases, fc2_weights, fc2_biases]\n",
    "            all_params_names = ['conv1_weights', 'conv1_biases', 'conv2_weights', 'conv2_biases', 'fc1_weights', 'fc1_biases', 'fc2_weights', 'fc2_biases']\n",
    "            all_grads_node = tf.gradients(loss, all_params_node)\n",
    "            all_grad_norms_node = []\n",
    "            for i in range(0, len(all_grads_node)):\n",
    "                norm_grad_i = tf.global_norm([all_grads_node[i]])\n",
    "                all_grad_norms_node.append(norm_grad_i)\n",
    "                tf.scalar_summary(all_params_names[i], norm_grad_i)\n",
    "\n",
    "            # L2 regularization for the fully connected parameters.\n",
    "            #### avoid extrploding weights (\"it only makes changes to the weights if they will really make a difference\")\n",
    "            regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                            tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "\n",
    "            # Add the regularization term to the loss.\n",
    "            loss += 5e-4 * regularizers\n",
    "\n",
    "            # Optimizer: set up a variable that's incremented once per batch and\n",
    "            # controls the learning rate decay.\n",
    "            batch = tf.Variable(0)\n",
    "            # Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "            learning_rate = tf.train.exponential_decay(\n",
    "                LEARNING_RATE,                # Base learning rate.\n",
    "                batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                train_size,          # Decay step.\n",
    "                DECAY_RATE,          # Decay rate. #### we use gradient descent, this is the decay of the step size\n",
    "                staircase=True)\n",
    "            tf.scalar_summary('learning_rate', learning_rate)\n",
    "\n",
    "            # Use simple momentum for the optimization.\n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                                   0.0).minimize(loss,\n",
    "                                                                 global_step=batch)\n",
    "\n",
    "            # Predictions for the minibatch, validation set and test set.\n",
    "            train_prediction = tf.nn.softmax(logits)\n",
    "            # We'll compute them only once in a while by calling their {eval()} method.\n",
    "            train_all_prediction = tf.nn.softmax(model(train_all_data_node,phase))\n",
    "\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            # Create a local session to run this computation.\n",
    "            with tf.Session() as s:\n",
    "\n",
    "                if RESTORE_MODEL:\n",
    "                    # Restore variables from disk.\n",
    "                    saver.restore(s, FLAGS.train_dir + \"/model.ckpt\")\n",
    "                    print(\"Model restored.\")\n",
    "\n",
    "                else:\n",
    "                    # Run all the initializers to prepare the trainable parameters.\n",
    "                    #tf.initialize_all_variables().run()\n",
    "                    tf.global_variables_initializer().run()\n",
    "\n",
    "                    # Build the summary operation based on the TF collection of Summaries.\n",
    "                    summary_op = tf.merge_all_summaries()\n",
    "                    print(\"OUTPUT DIR:\", FLAGS.train_dir)\n",
    "                    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\n",
    "                                                            graph=s.graph)\n",
    "                                                            #graph_def=s.graph_def)\n",
    "                    print ('Initialized!')\n",
    "                    # Loop through training steps.\n",
    "                    print ('Total number of iterations = ' + str(int(num_epochs * train_size / BATCH_SIZE)))\n",
    "\n",
    "                    training_indices = range(train_size)\n",
    "\n",
    "                    for iepoch in range(num_epochs):\n",
    "\n",
    "                        # Permute training indices\n",
    "                        perm_indices = numpy.random.permutation(training_indices)\n",
    "\n",
    "                        for step in range (int(train_size / BATCH_SIZE)):\n",
    "\n",
    "                            offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "                            batch_indices = perm_indices[offset:(offset + BATCH_SIZE)]\n",
    "\n",
    "                            # Compute the offset of the current minibatch in the data.\n",
    "                            # Note that we could use better randomization across epochs.\n",
    "                            batch_data = train_data[batch_indices, :, :, :]\n",
    "                            batch_labels = train_labels[batch_indices]\n",
    "                            # This dictionary maps the batch data (as a numpy array) to the\n",
    "                            # node in the graph is should be fed to.\n",
    "                            feed_dict = {train_data_node: batch_data,\n",
    "                                         train_labels_node: batch_labels}\n",
    "\n",
    "                            if step % RECORDING_STEP == 0:\n",
    "\n",
    "                                summary_str, _, l, lr, predictions = s.run(\n",
    "                                    [summary_op, optimizer, loss, learning_rate, train_prediction],\n",
    "                                    feed_dict=feed_dict)\n",
    "                                #summary_str = s.run(summary_op, feed_dict=feed_dict)\n",
    "                                summary_writer.add_summary(summary_str, step)\n",
    "                                summary_writer.flush()\n",
    "\n",
    "                                # print_predictions(predictions, batch_labels)\n",
    "\n",
    "                                print ('Epoch: ', iepoch,'.',step,', minibatch loss: %.3f' % (l), ', Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))\n",
    "\n",
    "                                sys.stdout.flush()\n",
    "                            else:\n",
    "                                # Run the graph and fetch some of the nodes.\n",
    "                                _, l, lr, predictions = s.run(\n",
    "                                    [optimizer, loss, learning_rate, train_prediction],\n",
    "                                    feed_dict=feed_dict)\n",
    "\n",
    "                        # Save the variables to disk.\n",
    "                        save_path = saver.save(s, FLAGS.train_dir + \"/model.ckpt\")\n",
    "                        print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "                print (\"Running prediction on training set\")\n",
    "                prediction_training_dir = \"predictions_training/\"\n",
    "                if not os.path.isdir(prediction_training_dir):\n",
    "                    os.mkdir(prediction_training_dir)\n",
    "                for i in range(1, TRAINING_SIZE+1):\n",
    "\n",
    "                    if phase ==1:\n",
    "                        image_filename = train_data_filename + \"satImage_%.3d\" % i + \".png\"\n",
    "                    if phase == 2:\n",
    "                        image_filename = train_data_filename + \"prediction_raw_\" + str(i) + \".png\" \n",
    "\n",
    "                    pimg = get_prediction_with_groundtruth(train_data_filename, i,phase)\n",
    "\n",
    "                    rimg = mpimg.imread(image_filename)\n",
    "                    rimg_prediction = get_prediction(rimg,phase)\n",
    "                    #convert from 2D array 1/0 to RGB\n",
    "                    w = rimg_prediction.shape[0]\n",
    "                    h = rimg_prediction.shape[1]\n",
    "                    rimg_mask = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "                    rimg_mask[:,:,0] = rimg_prediction*PIXEL_DEPTH\n",
    "                    rimg_mask[:,:,1] = rimg_prediction*PIXEL_DEPTH\n",
    "                    rimg_mask[:,:,2] = rimg_prediction*PIXEL_DEPTH\n",
    "                    rimg_final = Image.fromarray(rimg_mask, 'RGB')    \n",
    "                    \n",
    "                    oimg = get_prediction_with_overlay(train_data_filename, i,phase)\n",
    "                    \n",
    "                    if phase == 1:\n",
    "                        Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "                        rimg_final.save(prediction_training_dir + \"prediction_raw_\" + str(i) + \".png\")\n",
    "                        oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
    "                    if phase == 2:\n",
    "                        Image.fromarray(pimg).save(prediction_training_dir + \"prediction_2_\" + str(i) + \".png\")\n",
    "                        rimg_final.save(prediction_training_dir + \"prediction_raw_2_\" + str(i) + \".png\")\n",
    "                        oimg.save(prediction_training_dir + \"overlay_2_\" + str(i) + \".png\")\n",
    "\n",
    "            print(\"-- job done --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The variables below hold all the trainable weights. They are passed an\n",
    "# initial value which will be assigned when when we call:\n",
    "# {tf.initialize_all_variables().run()}\n",
    "\n",
    "#NOTE: Convolutional Neural Nets: we train one filter (output of y=exp(-w.T*x +b)) based on a sub-set of inputs, NOT ALL.\n",
    "#Our inputs are 3D (tile, tile, CHANNELS), one input per tile, so x is a 3D (5 tiles on X) * (5 tiles on Y) * NUM_CHANNELS subset of x\n",
    "cnn1 = CNN()\n",
    "cnn1.run(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: extract_data...\n",
      "train_data (before):  (7400, 40, 40, 3)\n",
      "extract_labels...\n",
      "train_labels (before):  (2,)\n",
      "Initial: number of data points per class: c0 = 4885 c1 = 2515\n",
      "Balancing training data...\n",
      "5030\n",
      "(7400, 40, 40, 3)\n",
      "train_data (after):  (5030, 40, 40, 3)\n",
      "train_labels (after):  (2,)\n",
      "After Balancing: Number of data points per class: c0 = 2515 c1 = 2515\n",
      "train_all_data_node (5030, 40, 40, 3)\n",
      "train_data_node: (16, 40, 40, 3)\n",
      "==== train: True\n",
      "data:  (16, 40, 40, 3)\n",
      "conv:  (16, 40, 40, 32)\n",
      "conv1_biases: (32,)\n",
      "conv1_weights: (5, 5, 3, 32)\n",
      "relu:  (16, 40, 40, 32)\n",
      "pool:  (16, 20, 20, 32)\n",
      "conv2:  (16, 20, 20, 64)\n",
      "conv2_biases: (64,)\n",
      "conv2_weights: (5, 5, 32, 64)\n",
      "relu2:  (16, 20, 20, 64)\n",
      "pool2: (16, 10, 10, 64)\n",
      "reshape: (16, 6400)\n",
      "fc1_weights: (6400, 512)\n",
      "hidden: (16, 512)\n",
      "fc2_weights: (512, 2)\n",
      "out: (16, 2)\n",
      "logits = (16, 2)  train_labels_node =  (16, 2)\n",
      "WARNING:tensorflow:From <ipython-input-5-f5a72619542f>:310 in run.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "OUTPUT DIR: ./tmp/\n",
      "Initialized!\n",
      "Total number of iterations = 314\n",
      "Epoch:  0 . 0 , minibatch loss: 10.692 , Minibatch error: 56.2%\n",
      "Model saved in file: ./tmp//model.ckpt\n",
      "Running prediction on training set\n",
      "-- job done --\n"
     ]
    }
   ],
   "source": [
    "IMG_PATCH_SIZE = 40 #should be a multiple of 4 and img_size (400)\n",
    "CONV1_FILTER_SIZE = 5 # size of X*Y filter in conv1\n",
    "CONV2_FILTER_SIZE = 5 # size of X*Y filter in conv2\n",
    "CONV1_FILTER_DEPTH = 32 #depth of conv1_weights depth in conv1\n",
    "POOL1_FILTER_STRIDE = 2\n",
    "CONV2_FILTER_DEPTH = 64 #depth of conv2_weights depth in conv2\n",
    "POOL2_FILTER_STRIDE = 2\n",
    "FC1_WEIGHTS_DEPTH = 512 #depht of weights in fc1\n",
    "LEARNING_RATE = 0.05 #0.01\n",
    "DECAY_RATE = 0.95 #decay of step size of gradient descent\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "cnn2 = CNN()\n",
    "cnn2.run(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask_to_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = IMG_PATCH_SIZE\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "submission_filename = 'dummy_submission.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'training/groundtruth/satImage_' + '%.3d' % i + '.png'\n",
    "    print image_filename\n",
    "    image_filenames.append(image_filename)\n",
    "    \n",
    "masks_to_submission(submission_filename, *image_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################## from Log regression code ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
